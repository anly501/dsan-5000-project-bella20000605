<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Bella Shi’s Website - Naive Bayes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Naive Bayes.html">Naive Bayes</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bella Shi’s Website</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="https://bella.georgetown.domains/about/" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About me</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Code.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Code</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Gathering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Gathering</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Cleaning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Exploration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Exploration</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Naive Bayes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Naive Bayes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dimensionality Reduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Classfication.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Classfication</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ARM.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ARM</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Conclusions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Conclusions</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#hw-3.2.0-introduction-to-naive-bayes" id="toc-hw-3.2.0-introduction-to-naive-bayes" class="nav-link active" data-scroll-target="#hw-3.2.0-introduction-to-naive-bayes">HW-3.2.0: Introduction to Naive Bayes</a></li>
  <li><a href="#hw-3.2.1-prepare-your-data-for-naïve-bayes" id="toc-hw-3.2.1-prepare-your-data-for-naïve-bayes" class="nav-link" data-scroll-target="#hw-3.2.1-prepare-your-data-for-naïve-bayes">HW-3.2.1: Prepare your Data for Naïve Bayes</a></li>
  <li><a href="#hw-3.2.2-feature-selection" id="toc-hw-3.2.2-feature-selection" class="nav-link" data-scroll-target="#hw-3.2.2-feature-selection">HW-3.2.2: Feature selection</a>
  <ul class="collapse">
  <li><a href="#hw-3.2.3-naïve-bayes-nb-with-labeled-record-data" id="toc-hw-3.2.3-naïve-bayes-nb-with-labeled-record-data" class="nav-link" data-scroll-target="#hw-3.2.3-naïve-bayes-nb-with-labeled-record-data">HW-3.2.3: Naïve Bayes (NB) with Labeled Record Data</a></li>
  </ul></li>
  <li><a href="#hw-3.2.4-naïve-bayes-nb-with-labeled-text-data" id="toc-hw-3.2.4-naïve-bayes-nb-with-labeled-text-data" class="nav-link" data-scroll-target="#hw-3.2.4-naïve-bayes-nb-with-labeled-text-data">HW-3.2.4: Naïve Bayes (NB) with Labeled Text Data</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Naive Bayes</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="hw-3.2.0-introduction-to-naive-bayes" class="level2">
<h2 class="anchored" data-anchor-id="hw-3.2.0-introduction-to-naive-bayes">HW-3.2.0: Introduction to Naive Bayes</h2>
<p>Naive Bayes classification is a probabilistic machine learning model that’s based on Bayes’ Theorem. It’s called “naive” because it assumes that the presence (or absence) of a particular feature of a class is unrelated to the presence (or absence) of any other feature, even if these features depend on each other. This simplification makes Naive Bayes easy to build and particularly useful for very large datasets.</p>
<section id="bayes-theorem-foundation" class="level4">
<h4 class="anchored" data-anchor-id="bayes-theorem-foundation"><b>Bayes’ Theorem Foundation</b><br></h4>
<p>At its core, Naive Bayes relies on Bayes’ Theorem, which describes the probability of an event, based on prior knowledge of conditions that might be related to the event. For classification, Bayes’ Theorem is stated as:</p>
<p><span class="math display">\[\begin{equation}
P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}
\end{equation}\]</span></p>
<p>Here,P(B|A) is the probability of hypothesis A given data B. P(B|A) is the probability of the data under the hypothesis, P(A) is the probability of the hypothesis before seeing the data, and P(B) is the probability of the data under any hypothesis.</p>
</section>
<section id="objectives-of-naive-bayes-classification" class="level4">
<h4 class="anchored" data-anchor-id="objectives-of-naive-bayes-classification"><b>Objectives of Naive Bayes Classification</b><br></h4>
<p>The objective in Naive Bayes is to determine the probability of a label given a set of features, and then predict the label with the highest probability. In other words, we calculate the posterior probability of each class given the input features and predict the class for which the posterior probability is the highest.</p>
</section>
<section id="what-naive-bayes-aims-to-achieve" class="level4">
<h4 class="anchored" data-anchor-id="what-naive-bayes-aims-to-achieve"><b>What Naive Bayes Aims to achieve</b><br></h4>
<p>Naive Bayes aims to model the conditional probability of the class labels given the features in order to make predictions. It’s particularly advantageous in situations where the dimensionality of the input space is high, as it avoids the curse of dimensionality to a certain extent due to its feature independence assumption</p>
</section>
<section id="variants-of-naive-bayes" class="level4">
<h4 class="anchored" data-anchor-id="variants-of-naive-bayes"><b>Variants of Naive Bayes</b><br></h4>
<p>There are several variants of the Naive Bayes classifier, each appropriate for a different type of dataset:</p>
<ol type="1">
<li>Gaussian Naive Bayes:</li>
</ol>
<p>Used when features have a continuous distribution and an assumption of normal distribution (Gaussian) is reasonable. Appropriate for many real-world problems, like predicting whether a given email is spam or not.</p>
<ol start="2" type="1">
<li>Multinomial Naive Bayes:</li>
</ol>
<p>Used for discrete data where features represent counts or frequency counts of events. Often used in text classification, where the features are related to word counts or frequencies within the documents.</p>
<ol start="3" type="1">
<li>Bernoulli Naive Bayes:</li>
</ol>
<p>Used when features are binary (i.e., they take only two values like true and false). Suitable for making predictions from binary features, like if a word occurs in a document or not, which is a common scenario in text classification problems.</p>
</section>
</section>
<section id="hw-3.2.1-prepare-your-data-for-naïve-bayes" class="level2">
<h2 class="anchored" data-anchor-id="hw-3.2.1-prepare-your-data-for-naïve-bayes">HW-3.2.1: Prepare your Data for Naïve Bayes</h2>
<p>1.Handle missing values</p>
<p>2.Encode the ‘Income group’ and ‘Continent’ categorical variables into a numerical format suitable for machine learning models.</p>
<p>3.Split the data into training and test sets</p>
<div class="cell" data-execution_count="268">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> missingno <span class="im">as</span> msno</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>df_mental_health<span class="op">=</span>pd.read_csv(<span class="st">'./Data/mental_health.csv'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Check missing values in the dataset</p>
<div class="cell" data-execution_count="269">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>missing_data<span class="op">=</span>df_mental_health.isnull().<span class="bu">sum</span>()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Economy                                                             0
Code                                                                0
Year                                                                0
Schizophrenia (%)                                                   0
Bipolar disorder (%)                                                0
Eating disorders (%)                                                0
Anxiety disorders (%)                                               0
Depression (%)                                                      0
Income group                                                       56
average_learning_Adjusted_of_school                               812
Continent                                                         588
GDP(2022)                                                         224
not_at_all_comfortable_speaking_anxiety_or_depression_percent    2380
dtype: int64</code></pre>
</div>
</div>
<section id="handle-missing-values" class="level5">
<h5 class="anchored" data-anchor-id="handle-missing-values">1.Handle missing values</h5>
<p>a.Dropping columns with more than 1000 null values</p>
<p>(We don’t Remove Rows with Missing Values because although this is the simplest approach, but it can lead to a significant reduction in data size, which might not be ideal if the missing data is extensive.)</p>
<p>so after this step, we dropped the column not_at_all_comfortable_speaking_anxiety_or_depression_percent</p>
<div class="cell" data-execution_count="270">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># Set the threshold for the minimum number of non-NA values required</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>df_mental_health <span class="op">=</span> df_mental_health.dropna(axis<span class="op">=</span><span class="dv">1</span>, thresh<span class="op">=</span>(<span class="bu">len</span>(df_mental_health) <span class="op">-</span> threshold))</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the columns remaining after the operation</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> df_mental_health.isnull().<span class="bu">sum</span>()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_data)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>Nr0<span class="op">=</span><span class="bu">len</span>(df_mental_health.index)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>Nc0<span class="op">=</span><span class="bu">len</span>(df_mental_health.columns)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Nrows = "</span>,Nr0,<span class="st">"</span><span class="ch">\n</span><span class="st">Ncol="</span>,Nc0,<span class="st">"</span><span class="ch">\n</span><span class="st">Matrix entries = "</span>, Nr0<span class="op">*</span>Nc0)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># missing_data1 = encoded_data1.isnull().sum()</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print(missing_data1)</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Economy                                  0
Code                                     0
Year                                     0
Schizophrenia (%)                        0
Bipolar disorder (%)                     0
Eating disorders (%)                     0
Anxiety disorders (%)                    0
Depression (%)                           0
Income group                            56
average_learning_Adjusted_of_school    812
Continent                              588
GDP(2022)                              224
dtype: int64
Nrows =  5488 
Ncol= 12 
Matrix entries =  65856</code></pre>
</div>
</div>
<p>b.Impute Missing Values:</p>
<p>Mean/Median/Mode Imputation: Replace missing values with the mean, median, or mode of the column. This is a common strategy for numerical data.</p>
<p>Forward or Backward Fill: For time-series data, we can fill missing values with the next or previous values.</p>
<p>Predictive Imputation: Use a machine learning algorithm to predict the missing values based on other data in the dataset.</p>
<p>Mean/Median Imputation: If the data is normally distributed, you might use the mean. If the distribution is skewed,the median might be more appropriate.</p>
<div class="cell" data-execution_count="271">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#1.plot the GDP(2022) in df_mental_health</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>sns.distplot(df_mental_health[<span class="st">'GDP(2022)'</span>])</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#2.plot the average_learning_Adjusted_of_school in df_mental_health</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>sns.distplot(df_mental_health[<span class="st">'average_learning_Adjusted_of_school'</span>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#3.although income group and df_mental_health also have a lot of missing values</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  but we can not plot  because it is a categorical variable</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/px/bhxss9d10zs_wzsv0ck6sb200000gn/T/ipykernel_19686/2527354667.py:4: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(df_mental_health['GDP(2022)'])
/var/folders/px/bhxss9d10zs_wzsv0ck6sb200000gn/T/ipykernel_19686/2527354667.py:7: UserWarning: 

`distplot` is a deprecated function and will be removed in seaborn v0.14.0.

Please adapt your code to use either `displot` (a figure-level function with
similar flexibility) or `histplot` (an axes-level function for histograms).

For a guide to updating your code to use the new functions, please see
https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751

  sns.distplot(df_mental_health['average_learning_Adjusted_of_school'])</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="271">
<pre><code>&lt;Axes: xlabel='average_learning_Adjusted_of_school', ylabel='Density'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Naive Bayes_files/figure-html/cell-5-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="Naive Bayes_files/figure-html/cell-5-output-4.png" class="img-fluid"></p>
</div>
</div>
<p>so here we impute missing values using the mean for GDP(2022) and the median for average_learning_Adjusted_of_school (assuming the distributions are appropriate for these measures):</p>
<div class="cell" data-execution_count="272">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values with the mean for GDP(2022)</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>df_mental_health[<span class="st">'GDP(2022)'</span>].fillna(df_mental_health[<span class="st">'GDP(2022)'</span>].mean(), inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Impute missing values with the median for average_learning_Adjusted_of_school</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>df_mental_health[<span class="st">'average_learning_Adjusted_of_school'</span>].fillna(df_mental_health[<span class="st">'average_learning_Adjusted_of_school'</span>].median(), inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>missing_data <span class="op">=</span> df_mental_health.isnull().<span class="bu">sum</span>()</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(missing_data)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>df_mental_health</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Economy                                  0
Code                                     0
Year                                     0
Schizophrenia (%)                        0
Bipolar disorder (%)                     0
Eating disorders (%)                     0
Anxiety disorders (%)                    0
Depression (%)                           0
Income group                            56
average_learning_Adjusted_of_school      0
Continent                              588
GDP(2022)                                0
dtype: int64</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="272">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Economy</th>
<th data-quarto-table-cell-role="th">Code</th>
<th data-quarto-table-cell-role="th">Year</th>
<th data-quarto-table-cell-role="th">Schizophrenia (%)</th>
<th data-quarto-table-cell-role="th">Bipolar disorder (%)</th>
<th data-quarto-table-cell-role="th">Eating disorders (%)</th>
<th data-quarto-table-cell-role="th">Anxiety disorders (%)</th>
<th data-quarto-table-cell-role="th">Depression (%)</th>
<th data-quarto-table-cell-role="th">Income group</th>
<th data-quarto-table-cell-role="th">average_learning_Adjusted_of_school</th>
<th data-quarto-table-cell-role="th">Continent</th>
<th data-quarto-table-cell-role="th">GDP(2022)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Afghanistan</td>
<td>AFG</td>
<td>1990</td>
<td>0.160560</td>
<td>0.697779</td>
<td>0.101855</td>
<td>4.828830</td>
<td>4.071831</td>
<td>Low income</td>
<td>4.957542</td>
<td>Asia</td>
<td>14583.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Afghanistan</td>
<td>AFG</td>
<td>1991</td>
<td>0.160312</td>
<td>0.697961</td>
<td>0.099313</td>
<td>4.829740</td>
<td>4.079531</td>
<td>Low income</td>
<td>4.957542</td>
<td>Asia</td>
<td>14583.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Afghanistan</td>
<td>AFG</td>
<td>1992</td>
<td>0.160135</td>
<td>0.698107</td>
<td>0.096692</td>
<td>4.831108</td>
<td>4.088358</td>
<td>Low income</td>
<td>4.957542</td>
<td>Asia</td>
<td>14583.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Afghanistan</td>
<td>AFG</td>
<td>1993</td>
<td>0.160037</td>
<td>0.698257</td>
<td>0.094336</td>
<td>4.830864</td>
<td>4.096190</td>
<td>Low income</td>
<td>4.957542</td>
<td>Asia</td>
<td>14583.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Afghanistan</td>
<td>AFG</td>
<td>1994</td>
<td>0.160022</td>
<td>0.698469</td>
<td>0.092439</td>
<td>4.829423</td>
<td>4.099582</td>
<td>Low income</td>
<td>4.957542</td>
<td>Asia</td>
<td>14583.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5483</td>
<td>Zimbabwe</td>
<td>ZWE</td>
<td>2013</td>
<td>0.155670</td>
<td>0.607993</td>
<td>0.117248</td>
<td>3.090168</td>
<td>3.128192</td>
<td>Lower middle income</td>
<td>6.799749</td>
<td>Africa</td>
<td>20678.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5484</td>
<td>Zimbabwe</td>
<td>ZWE</td>
<td>2014</td>
<td>0.155993</td>
<td>0.608610</td>
<td>0.118073</td>
<td>3.093964</td>
<td>3.140290</td>
<td>Lower middle income</td>
<td>6.799749</td>
<td>Africa</td>
<td>20678.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5485</td>
<td>Zimbabwe</td>
<td>ZWE</td>
<td>2015</td>
<td>0.156465</td>
<td>0.609363</td>
<td>0.119470</td>
<td>3.098687</td>
<td>3.155710</td>
<td>Lower middle income</td>
<td>6.799749</td>
<td>Africa</td>
<td>20678.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5486</td>
<td>Zimbabwe</td>
<td>ZWE</td>
<td>2016</td>
<td>0.157111</td>
<td>0.610234</td>
<td>0.121456</td>
<td>3.104294</td>
<td>3.174134</td>
<td>Lower middle income</td>
<td>6.799749</td>
<td>Africa</td>
<td>20678.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5487</td>
<td>Zimbabwe</td>
<td>ZWE</td>
<td>2017</td>
<td>0.157963</td>
<td>0.611242</td>
<td>0.124443</td>
<td>3.110926</td>
<td>3.192789</td>
<td>Lower middle income</td>
<td>6.799749</td>
<td>Africa</td>
<td>20678.0</td>
</tr>
</tbody>
</table>

<p>5488 rows × 12 columns</p>
</div>
</div>
</div>
<ol start="3" type="a">
<li>Drop Rows (‘Income group’) with Missing Values:</li>
</ol>
<p>The ‘Income group’ and ‘Continent’ columns still have missing values. Before we proceed with the Naive Bayes classification, we need to address these missing values. Since ‘Income group’ will be our target variable for classification, we cannot impute it as we did with the continuous variables. Instead, we should remove the rows with missing ‘Income group’ labels.</p>
<p>As for the ‘Continent’ column, it might not be necessary for our classification model if we’re using economic and health indicators as features.(because we can just dont choose the feature in the feature selection). However, if we decide that continent information might be useful, we could either impute the missing values based on the ‘Economy’ column or drop the column if it’s not required.</p>
<div class="cell" data-execution_count="273">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropping rows where 'Income group' is missing since it's our target variable</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>df_mental_health <span class="op">=</span> df_mental_health.dropna(subset<span class="op">=</span>[<span class="st">'Income group'</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># # Dropping the 'Continent' column</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># data_cleaned = df_mental_health.drop('Continent', axis=1)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Verifying that there are no more missing values</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>missing_values_final <span class="op">=</span> df_mental_health.isnull().<span class="bu">sum</span>()</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>missing_values_final, df_mental_health.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="273">
<pre><code>(Economy                                  0
 Code                                     0
 Year                                     0
 Schizophrenia (%)                        0
 Bipolar disorder (%)                     0
 Eating disorders (%)                     0
 Anxiety disorders (%)                    0
 Depression (%)                           0
 Income group                             0
 average_learning_Adjusted_of_school      0
 Continent                              560
 GDP(2022)                                0
 dtype: int64,
 (5432, 12))</code></pre>
</div>
</div>
<p>The dataset is now clean and ready for classification. We can proceed with the next step.</p>
<div class="cell" data-execution_count="274">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the cleaned dataframe to a new CSV file</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># df_mental_health.to_csv('./mental_health_cleaned_not_encoded.csv', index=False)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>3.Encode the ‘Income group’ and ‘Continent’ categorical variables into a numerical format suitable for machine learning models and Split the data into training and test sets</p>
<div class="cell" data-execution_count="275">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># import pandas as pd</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.model_selection import train_test_split</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.preprocessing import LabelEncoder</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># # # Load the cleaned dataset</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># # file_path = './Data/mental_health.csv'</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co"># # data = pd.read_csv(file_path)</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># data= df_mental_health</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # Encoding the 'Income group' column to have numerical labels</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="co"># label_encoder = LabelEncoder()</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># data['Income group'] = label_encoder.fit_transform(data['Income group'])</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># # Selecting features and target variable</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># X = data.drop(['Economy', 'Code', 'Income group', 'Year', 'Continent'], axis=1)</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># y = data['Income group']</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># # Splitting the dataset into training (70%), validation (15%), and testing (15%) sets</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a><span class="co"># X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a><span class="co"># X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)</span></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># # Checking the shape of the datasets</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># (X_train.shape, X_val.shape, X_test.shape), (y_train.shape, y_val.shape, y_test.shape)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="hw-3.2.2-feature-selection" class="level2">
<h2 class="anchored" data-anchor-id="hw-3.2.2-feature-selection">HW-3.2.2: Feature selection</h2>
<p>Decide which features are relevant for our classification task(Naive Bayes model) and drop the rest.</p>
<p>The ‘Income group’ is a categorical variable that could be used as a label for classification, so we predict the ‘Income group’ based on health and economic indicators.</p>
<p>method: 1. EDA to find the correlation between the features and the target variable</p>
<p>Corralation matrix</p>
<div class="cell" data-execution_count="276">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_mental_health.columns)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># # Load the cleaned dataset</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># file_path = './Data/mental_health.csv'</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># data = pd.read_csv(file_path)</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>correlation_columns <span class="op">=</span> [</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Schizophrenia (%)'</span>, </span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Bipolar disorder (%)'</span>, </span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Eating disorders (%)'</span>, </span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Anxiety disorders (%)'</span>, </span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Depression (%)'</span>, </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'GDP(2022)'</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'average_learning_Adjusted_of_school'</span>,</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 'Income group',</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 'Continent',</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co"># One-hot encoding the 'Income group' and 'Continent' columns to include them in the correlation matrix</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>encoded_data <span class="op">=</span> pd.get_dummies(df_mental_health, columns<span class="op">=</span>[<span class="st">'Income group'</span>, <span class="st">'Continent'</span>])</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(encoded_data.head())</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="co"># encoded_data.to_csv('./mental_health_encoded.csv', index=False)</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Updating the correlation_columns list to include the newly created one-hot encoded columns</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>new_correlation_columns <span class="op">=</span> correlation_columns <span class="op">+</span> <span class="bu">list</span>(encoded_data.columns[encoded_data.columns.<span class="bu">str</span>.startswith(<span class="st">'Income group_'</span>)]) <span class="op">+</span> <span class="bu">list</span>(encoded_data.columns[encoded_data.columns.<span class="bu">str</span>.startswith(<span class="st">'Continent_'</span>)])</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the new correlation matrix including the one-hot encoded columns</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>new_correlation_matrix <span class="op">=</span> encoded_data[new_correlation_columns].corr()</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a mask for the upper triangle</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.triu(np.ones_like(new_correlation_matrix, dtype<span class="op">=</span><span class="bu">bool</span>))</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up the matplotlib figure</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw the heatmap with the mask</span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>sns.heatmap(new_correlation_matrix, mask<span class="op">=</span>mask, annot<span class="op">=</span><span class="va">False</span>, fmt<span class="op">=</span><span class="st">".2f"</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, cbar_kws<span class="op">=</span>{<span class="st">"shrink"</span>: <span class="fl">.5</span>})</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Add title</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Correlation Heatmap for Mental Health Metrics with Categorical Variables'</span>)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the heatmap</span></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(encoded_data.head())</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(encoded_data))</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a><span class="co"># print(new_correlation_matrix)</span></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Index(['Economy', 'Code', 'Year', 'Schizophrenia (%)', 'Bipolar disorder (%)',
       'Eating disorders (%)', 'Anxiety disorders (%)', 'Depression (%)',
       'Income group', 'average_learning_Adjusted_of_school', 'Continent',
       'GDP(2022)'],
      dtype='object')
       Economy Code  Year  Schizophrenia (%)  Bipolar disorder (%)  \
0  Afghanistan  AFG  1990           0.160560              0.697779   
1  Afghanistan  AFG  1991           0.160312              0.697961   
2  Afghanistan  AFG  1992           0.160135              0.698107   
3  Afghanistan  AFG  1993           0.160037              0.698257   
4  Afghanistan  AFG  1994           0.160022              0.698469   

   Eating disorders (%)  Anxiety disorders (%)  Depression (%)  \
0              0.101855               4.828830        4.071831   
1              0.099313               4.829740        4.079531   
2              0.096692               4.831108        4.088358   
3              0.094336               4.830864        4.096190   
4              0.092439               4.829423        4.099582   

   average_learning_Adjusted_of_school  GDP(2022)  Income group_High income  \
0                             4.957542    14583.0                         0   
1                             4.957542    14583.0                         0   
2                             4.957542    14583.0                         0   
3                             4.957542    14583.0                         0   
4                             4.957542    14583.0                         0   

   Income group_Low income  Income group_Lower middle income  \
0                        1                                 0   
1                        1                                 0   
2                        1                                 0   
3                        1                                 0   
4                        1                                 0   

   Income group_Upper middle income  Continent_Africa  Continent_Asia  \
0                                 0                 0               1   
1                                 0                 0               1   
2                                 0                 0               1   
3                                 0                 0               1   
4                                 0                 0               1   

   Continent_Europe  Continent_North America  Continent_Oceania  \
0                 0                        0                  0   
1                 0                        0                  0   
2                 0                        0                  0   
3                 0                        0                  0   
4                 0                        0                  0   

   Continent_South America  
0                        0  
1                        0  
2                        0  
3                        0  
4                        0  
       Economy Code  Year  Schizophrenia (%)  Bipolar disorder (%)  \
0  Afghanistan  AFG  1990           0.160560              0.697779   
1  Afghanistan  AFG  1991           0.160312              0.697961   
2  Afghanistan  AFG  1992           0.160135              0.698107   
3  Afghanistan  AFG  1993           0.160037              0.698257   
4  Afghanistan  AFG  1994           0.160022              0.698469   

   Eating disorders (%)  Anxiety disorders (%)  Depression (%)  \
0              0.101855               4.828830        4.071831   
1              0.099313               4.829740        4.079531   
2              0.096692               4.831108        4.088358   
3              0.094336               4.830864        4.096190   
4              0.092439               4.829423        4.099582   

   average_learning_Adjusted_of_school  GDP(2022)  Income group_High income  \
0                             4.957542    14583.0                         0   
1                             4.957542    14583.0                         0   
2                             4.957542    14583.0                         0   
3                             4.957542    14583.0                         0   
4                             4.957542    14583.0                         0   

   Income group_Low income  Income group_Lower middle income  \
0                        1                                 0   
1                        1                                 0   
2                        1                                 0   
3                        1                                 0   
4                        1                                 0   

   Income group_Upper middle income  Continent_Africa  Continent_Asia  \
0                                 0                 0               1   
1                                 0                 0               1   
2                                 0                 0               1   
3                                 0                 0               1   
4                                 0                 0               1   

   Continent_Europe  Continent_North America  Continent_Oceania  \
0                 0                        0                  0   
1                 0                        0                  0   
2                 0                        0                  0   
3                 0                        0                  0   
4                 0                        0                  0   

   Continent_South America  
0                        0  
1                        0  
2                        0  
3                        0  
4                        0  
&lt;class 'pandas.core.frame.DataFrame'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Naive Bayes_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>Strong Correlation: Values above 0.7 or below -0.7 suggest a strong correlation between the variables. Moderate Correlation: Values between 0.3 and 0.7 (or -0.3 and -0.7) suggest a moderate correlation. Weak Correlation: Values between 0 and 0.3 (or 0 and -0.3) suggest a weak correlation.</p>
<ol start="2" type="1">
<li>Pearson Correlation</li>
</ol>
<p>The Pearson correlation coefficients you’ve provided show the linear relationship between each feature and the ‘Income group’ target variable. A coefficient close to 1 or -1 indicates a strong positive or negative linear relationship, respectively. A coefficient close to 0 suggests no linear relationship.</p>
<div class="cell" data-execution_count="277">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print(df_mental_health.isnull().sum())</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # Load the cleaned dataset df_mental_health</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># For Pearson Correlation, we would ideally have only numeric features and labels</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># so we will encode the categorical features (Income group and Continent) using LabelEncoder</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Income group' column to have numerical labels</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>df_mental_health[<span class="st">'Income group'</span>] <span class="op">=</span> label_encoder.fit_transform(df_mental_health[<span class="st">'Income group'</span>])</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Continent' column to have numerical labels</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>df_mental_health[<span class="st">'Continent'</span>] <span class="op">=</span> label_encoder.fit_transform(df_mental_health[<span class="st">'Continent'</span>])</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the Pearson Correlation matrix</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>correlation_matrix <span class="op">=</span> df_mental_health.corr()</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print(correlation_matrix)</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Selecting only correlations with the target variable (assuming target is numeric)</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>target_correlation <span class="op">=</span> correlation_matrix[<span class="st">'Income group'</span>].sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Review the correlations and decide on a threshold for selecting features</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(target_correlation)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate the inter-correlations with other features</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># For multicollinearity, we could remove features that have a high correlation with other features</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>threshold <span class="op">=</span> <span class="fl">0.8</span>  <span class="co"># This is an example threshold, it may need to be adjusted</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>high_correlation_pairs <span class="op">=</span> []</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(correlation_matrix.columns)):</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, <span class="bu">len</span>(correlation_matrix.columns)):</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">abs</span>(correlation_matrix.iloc[i, j]) <span class="op">&gt;</span> threshold:</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>            high_correlation_pairs.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(high_correlation_pairs)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Income group                           1.000000e+00
Year                                   1.892221e-14
GDP(2022)                             -9.632665e-03
Continent                             -9.004944e-02
Depression (%)                        -2.334807e-01
Bipolar disorder (%)                  -2.752850e-01
average_learning_Adjusted_of_school   -3.443070e-01
Anxiety disorders (%)                 -3.575221e-01
Schizophrenia (%)                     -3.745985e-01
Eating disorders (%)                  -5.301981e-01
Name: Income group, dtype: float64
[]</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/px/bhxss9d10zs_wzsv0ck6sb200000gn/T/ipykernel_19686/1110566272.py:16: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_mental_health['Income group'] = label_encoder.fit_transform(df_mental_health['Income group'])
/var/folders/px/bhxss9d10zs_wzsv0ck6sb200000gn/T/ipykernel_19686/1110566272.py:18: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df_mental_health['Continent'] = label_encoder.fit_transform(df_mental_health['Continent'])
/var/folders/px/bhxss9d10zs_wzsv0ck6sb200000gn/T/ipykernel_19686/1110566272.py:21: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  correlation_matrix = df_mental_health.corr()</code></pre>
</div>
</div>
<p>Now, we can decide which features to drop based on their correlation with the target and their inter-correlations with other features</p>
<p>Eating disorders (%): With a correlation coefficient of approximately -0.53, this feature has the strongest negative linear relationship with the ‘Income group’ and is likely to be the most informative for predicting income group.</p>
<p>Anxiety disorders (%), Schizophrenia (%), average_learning_Adjusted_of_school, Bipolar disorder (%), and Depression (%): All of these features have moderate negative correlations with the ‘Income group’, meaning as these percentages increase, the likelihood of being in a higher income group decreases.</p>
<p>GDP(2022) and Continent: This feature has a very weak negative correlation with the ‘Income group’, suggesting it might not be very useful for predicting the income group on its own. so we drop this feature</p>
<p>Year: The correlation is effectively zero, indicating no linear relationship with the ‘Income group’. sp we drop this feature.</p>
<p>So in this example, features excluding ‘Year’ and ‘GDP(2022)’ and ’Continent” are used for classification.</p>
<p>The ‘Year’ column is dropped because it’s not relevant for classification, and ‘GDP(2022)’ and ‘Continent” are dropped because it has a very weak correlation with the ’Income group’ and is unlikely to be useful for classification.</p>
<section id="hw-3.2.3-naïve-bayes-nb-with-labeled-record-data" class="level3">
<h3 class="anchored" data-anchor-id="hw-3.2.3-naïve-bayes-nb-with-labeled-record-data">HW-3.2.3: Naïve Bayes (NB) with Labeled Record Data</h3>
<div class="cell" data-execution_count="278">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, classification_report, confusion_matrix</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print(df_mental_health.info())</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Selecting features and target variable</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(X.columns)</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_mental_health.drop([<span class="st">'Economy'</span>, <span class="st">'Code'</span>, <span class="st">'Income group'</span>, <span class="st">'Year'</span>, <span class="st">'Continent'</span>,<span class="st">'GDP(2022)'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_mental_health[<span class="st">'Income group'</span>]</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X.columns)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the dataset into training (70%), validation (15%), and testing (15%) sets</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>X_train, X_temp, y_train, y_temp <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>X_val, X_test, y_val, y_test <span class="op">=</span> train_test_split(X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking the shape of the datasets</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>(X_train.shape, X_val.shape, X_test.shape), (y_train.shape, y_val.shape, y_test.shape)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the Naïve Bayes model</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>nb_classifier <span class="op">=</span> GaussianNB()</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>nb_classifier.fit(X_train, y_train)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Validate the model</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>y_val_pred <span class="op">=</span> nb_classifier.predict(X_val)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>val_accuracy <span class="op">=</span> accuracy_score(y_val, y_val_pred)</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>val_classification_report <span class="op">=</span> classification_report(y_val, y_val_pred)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>val_confusion_matrix <span class="op">=</span> confusion_matrix(y_val, y_val_pred)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the confusion matrix</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>sns.heatmap(val_confusion_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for Validation Set'</span>)</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model using the validation set</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation Accuracy: </span><span class="sc">{</span>val_accuracy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Classification Report for Validation Set:</span><span class="ch">\n</span><span class="sc">{</span>val_classification_report<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Index(['Schizophrenia (%)', 'Bipolar disorder (%)', 'Eating disorders (%)',
       'Anxiety disorders (%)', 'Depression (%)',
       'average_learning_Adjusted_of_school'],
      dtype='object')
Validation Accuracy: 0.6282208588957056
Classification Report for Validation Set:
              precision    recall  f1-score   support

           0       0.88      0.56      0.69       272
           1       0.63      0.86      0.73        94
           2       0.66      0.62      0.64       227
           3       0.46      0.62      0.53       222

    accuracy                           0.63       815
   macro avg       0.66      0.67      0.64       815
weighted avg       0.67      0.63      0.63       815
</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="Naive Bayes_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="279">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test the model</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>y_test_pred <span class="op">=</span> nb_classifier.predict(X_test)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>test_accuracy <span class="op">=</span> accuracy_score(y_test, y_test_pred)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>test_classification_report <span class="op">=</span> classification_report(y_test, y_test_pred)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>test_confusion_matrix <span class="op">=</span> confusion_matrix(y_test, y_test_pred)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the confusion matrix for the test set</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>sns.heatmap(test_confusion_matrix, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Predicted'</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'True'</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix for Test Set'</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model using the test set</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Classification Report for Test Set:</span><span class="ch">\n</span><span class="sc">{</span>test_classification_report<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="Naive Bayes_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Accuracy: 0.645398773006135
Classification Report for Test Set:
              precision    recall  f1-score   support

           0       0.89      0.62      0.73       281
           1       0.67      0.89      0.76       102
           2       0.64      0.63      0.63       219
           3       0.46      0.58      0.51       213

    accuracy                           0.65       815
   macro avg       0.66      0.68      0.66       815
weighted avg       0.68      0.65      0.65       815
</code></pre>
</div>
</div>
</section>
</section>
<section id="hw-3.2.4-naïve-bayes-nb-with-labeled-text-data" class="level2">
<h2 class="anchored" data-anchor-id="hw-3.2.4-naïve-bayes-nb-with-labeled-text-data">HW-3.2.4: Naïve Bayes (NB) with Labeled Text Data</h2>
<p>Example1: predict the mental health condition based on the symptoms</p>
<ol type="1">
<li>The dataset is structured with two columns: ‘Symptoms’ and ‘Label’. load the dataset</li>
<li>Preprocess the text data in the ‘Symptoms’ column. This includes cleaning and tokenizing the text, normalizing it, and removing stop words.</li>
<li>Encode the ‘Label’ column to numerical values, as Naive Bayes requires numerical input.</li>
<li>Split the data into training and testing sets.</li>
<li>Train a Naive Bayes classifier on the training set.</li>
<li>Evaluate the model on the testing set.</li>
</ol>
<div class="cell" data-execution_count="280">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data from the uploaded CSV file</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>df_mental_health <span class="op">=</span> pd.read_csv(<span class="st">"./Data/all_mental_health_symptoms_nb.csv"</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>df_mental_health.head()  <span class="co"># Display the first few rows to understand the dataset structure</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="280">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Symptoms</th>
<th data-quarto-table-cell-role="th">Label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Feelings of sadness, tearfulness, emptiness or...</td>
<td>Depression</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Angry outbursts, irritability or frustration, ...</td>
<td>Depression</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>Loss of interest or pleasure in most or all no...</td>
<td>Depression</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>Sleep disturbances, including insomnia or slee...</td>
<td>Depression</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>Tiredness and lack of energy, so even small ta...</td>
<td>Depression</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="281">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocessing the text data</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>tfidf_vectorizer <span class="op">=</span> TfidfVectorizer(stop_words<span class="op">=</span><span class="st">'english'</span>, max_features<span class="op">=</span><span class="dv">1000</span>)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> tfidf_vectorizer.fit_transform(df_mental_health[<span class="st">'Symptoms'</span>]).toarray()</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Encoding the 'Label' column</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> label_encoder.fit_transform(df_mental_health[<span class="st">'Label'</span>])</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the data into training and testing sets</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Training the Naive Bayes classifier</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>nb_classifier <span class="op">=</span> MultinomialNB()</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>nb_classifier.fit(X_train, y_train)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting the test set results</span></span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb_classifier.predict(X_test)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluating the model calculating the testing accuracy</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'testing accuracy:'</span>,accuracy)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Predicting the training set results to calculate the training accuracy</span></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>y_train_pred <span class="op">=</span> nb_classifier.predict(X_train)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculating the training accuracy</span></span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>training_accuracy <span class="op">=</span> accuracy_score(y_train, y_train_pred)</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>training_accuracy</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'training accuracy:'</span>,training_accuracy)</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>report <span class="op">=</span> classification_report(y_test, y_pred, target_names<span class="op">=</span>label_encoder.classes_)</span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(report)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>testing accuracy: 0.3142857142857143
training accuracy: 0.9873417721518988
                  precision    recall  f1-score   support

         Anxiety       0.27      0.80      0.40         5
Bipolar Disorder       0.50      0.25      0.33         8
      Depression       0.20      0.12      0.15         8
 Eating Disorder       0.33      0.14      0.20         7
   Schizophrenia       0.38      0.43      0.40         7

        accuracy                           0.31        35
       macro avg       0.33      0.35      0.30        35
    weighted avg       0.34      0.31      0.29        35
</code></pre>
</div>
</div>
<p>The accuracy of the Naive Bayes model on the mental health symptoms dataset is not high: 0.31. This is likely due to the following factors:</p>
<ol type="1">
<li>Overlap of Symptoms: Many mental health conditions have overlapping symptoms, which can confuse the model. For example, symptoms like “anxiety” or “sleep disturbances” can occur in multiple disorders.</li>
</ol>
<p>Example2: predict if it descrbes a mental health problem based on the symptoms Preprocess the “Symptoms” text data with vectorization.</p>
<p>Encode the “Label” column into numerical values.</p>
<p>Split the data into a training set and a test set.</p>
<p>Train a Naive Bayes model. Evaluate the model on the test data.</p>
<div class="cell" data-execution_count="282">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> MultinomialNB</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, accuracy_score</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Attempt to read the CSV file while skipping problematic lines</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    new_data <span class="op">=</span> pd.read_csv(<span class="st">'./Data/mental_sports_nb.csv'</span>,on_bad_lines<span class="op">=</span><span class="st">'skip'</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Display the first few rows of the dataframe and the number of rows skipped</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    new_first_rows <span class="op">=</span> new_data.head()</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    new_num_rows <span class="op">=</span> new_data.shape[<span class="dv">0</span>]</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>    new_exception_message <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>    new_first_rows, new_num_rows, new_exception_message <span class="op">=</span> <span class="va">None</span>, <span class="va">None</span>, <span class="bu">str</span>(e)</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>new_first_rows, new_num_rows, new_exception_message</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the vectorizer and label encoder</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>vectorizer <span class="op">=</span> CountVectorizer()</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>label_encoder <span class="op">=</span> LabelEncoder()</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Vectorize the 'Symptoms' text</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> vectorizer.fit_transform(new_data[<span class="st">'Symptoms'</span>])</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode the 'Label' column</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> label_encoder.fit_transform(new_data[<span class="st">'Label'</span>])</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and test sets (80% train, 20% test)</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a Naive Bayes classifier</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>nb_classifier <span class="op">=</span> MultinomialNB()</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the classifier</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>nb_classifier.fit(X_train, y_train)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the test set</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb_classifier.predict(X_test)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the classifier</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>accuracy <span class="op">=</span> accuracy_score(y_test, y_pred)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>classification_rep <span class="op">=</span> classification_report(y_test, y_pred, target_names<span class="op">=</span>label_encoder.classes_)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(accuracy)</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_rep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9565217391304348
               precision    recall  f1-score   support

Mental Health       0.92      1.00      0.96        12
       Sports       1.00      0.91      0.95        11

     accuracy                           0.96        23
    macro avg       0.96      0.95      0.96        23
 weighted avg       0.96      0.96      0.96        23
</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>